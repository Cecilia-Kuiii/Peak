{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOadZ4+c1sFNzlwQWXfKStC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cecilia-Kuiii/Peak/blob/Master-FatherTree/paperanalysis/FedAvgFinalVersion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "w8zVuIkb-pme",
        "outputId": "0cdd6f9f-fb88-4cee-ee0c-ce986166f6c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRw7PnhB-_WX",
        "outputId": "9e2cf25c-5973-403c-8d63-e55da0fcfca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jan 24 15:44:02 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P0              30W /  70W |    103MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PKebcAhH_av_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Dua0ySj1_5Ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import copy                 # 用于联邦学习全局模型的复制过程\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "import torch\n",
        "import argparse\n",
        "# 自定义文件的调用\n",
        "from utils.sampling import mnist_iid, mnist_noniid, cifar_iid\n",
        "from utils.options import args_parser\n",
        "from models.Update import LocalUpdate\n",
        "from models.Nets import MLP, CNNMnist, CNNCifar\n",
        "from models.Fed import FedAvg\n",
        "from models.test import test_img"
      ],
      "metadata": {
        "id": "_t6B1sPSAGAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # parse args\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    parser.add_argument('--epochs', type=int, default=20, help=\"rounds of training\")\n",
        "    parser.add_argument('--num_users', type=int, default=100, help=\"number of users: K\")\n",
        "    parser.add_argument('--frac', type=float, default=0.1, help=\"the fraction of clients: C\")\n",
        "    parser.add_argument('--local_ep', type=int, default=5, help=\"the number of local epochs: E\")\n",
        "    parser.add_argument('--local_bs', type=int, default=10, help=\"local batch size: B\")\n",
        "    parser.add_argument('--bs', type=int, default=128, help=\"test batch size\")\n",
        "    parser.add_argument('--lr', type=float, default=0.01, help=\"learning rate\")\n",
        "    parser.add_argument('--momentum', type=float, default=0.5, help=\"SGD momentum (default: 0.5)\")\n",
        "    parser.add_argument('--split', type=str, default='user', help=\"train-test split type, user or sample\")\n",
        "\n",
        "    # model arguments\n",
        "    parser.add_argument('--model', type=str, default='mlp', help='model name')\n",
        "    parser.add_argument('--kernel_num', type=int, default=9, help='number of each kind of kernel')\n",
        "    parser.add_argument('--kernel_sizes', type=str, default='3,4,5',\n",
        "                        help='comma-separated kernel size to use for convolution')\n",
        "    parser.add_argument('--norm', type=str, default='batch_norm', help=\"batch_norm, layer_norm, or None\")\n",
        "    parser.add_argument('--num_filters', type=int, default=32, help=\"number of filters for conv nets\")\n",
        "    parser.add_argument('--max_pool', type=str, default='True',\n",
        "                        help=\"Whether use max pooling rather than strided convolutions\")\n",
        "\n",
        "    # other arguments\n",
        "    parser.add_argument('--dataset', type=str, default='mnist', help=\"name of dataset\")\n",
        "    parser.add_argument('--iid', action='store_true', help='whether i.i.d or not')\n",
        "    parser.add_argument('--num_classes', type=int, default=10, help=\"number of classes\")\n",
        "    parser.add_argument('--num_channels', type=int, default=3, help=\"number of channels of imges\")\n",
        "    parser.add_argument('--gpu', type=int, default=0, help=\"GPU ID, -1 for CPU\")\n",
        "    parser.add_argument('--stopping_rounds', type=int, default=10, help='rounds of early stopping')\n",
        "    parser.add_argument('--verbose', action='store_true', help='verbose print')\n",
        "    parser.add_argument('--seed', type=int, default=1, help='random seed (default: 1)')\n",
        "    parser.add_argument('--all_clients', action='store_true', help='aggregation over all clients')\n",
        "    args = parser.parse_args([])\n",
        "    args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() and args.gpu != -1 else 'cpu')\n",
        "\n",
        "    # load dataset and split users\n",
        "    if args.dataset == 'mnist':\n",
        "        trans_mnist = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "        dataset_train = datasets.MNIST('../data/mnist/', train=True, download=True, transform=trans_mnist)\n",
        "        dataset_test = datasets.MNIST('../data/mnist/', train=False, download=True, transform=trans_mnist)\n",
        "        # sample users\n",
        "        if args.iid:\n",
        "            dict_users = mnist_iid(dataset_train, args.num_users)\n",
        "        else:\n",
        "            dict_users = mnist_noniid(dataset_train, args.num_users)\n",
        "    elif args.dataset == 'cifar':\n",
        "        trans_cifar = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "        dataset_train = datasets.CIFAR10('../data/cifar', train=True, download=True, transform=trans_cifar)\n",
        "        dataset_test = datasets.CIFAR10('../data/cifar', train=False, download=True, transform=trans_cifar)\n",
        "        if args.iid:\n",
        "            dict_users = cifar_iid(dataset_train, args.num_users)\n",
        "        else:\n",
        "            exit('Error: only consider IID setting in CIFAR10')\n",
        "    else:\n",
        "        exit('Error: unrecognized dataset')\n",
        "    img_size = dataset_train[0][0].shape\n",
        "\n",
        "    # build model\n",
        "    if args.model == 'cnn' and args.dataset == 'cifar':\n",
        "        net_glob = CNNCifar(args=args).to(args.device)\n",
        "    elif args.model == 'cnn' and args.dataset == 'mnist':\n",
        "        net_glob = CNNMnist(args=args).to(args.device)\n",
        "    elif args.model == 'mlp':\n",
        "        len_in = 1\n",
        "        for x in img_size:\n",
        "            len_in *= x\n",
        "        net_glob = MLP(dim_in=len_in, dim_hidden=200, dim_out=args.num_classes).to(args.device)\n",
        "    else:\n",
        "        exit('Error: unrecognized model')\n",
        "    print(net_glob)\n",
        "    net_glob.train()\n",
        "\n",
        "    # copy weights\n",
        "    w_glob = net_glob.state_dict()\n",
        "\n",
        "    # training\n",
        "    loss_train = []\n",
        "    cv_loss, cv_acc = [], []\n",
        "    val_loss_pre, counter = 0, 0\n",
        "    net_best = None\n",
        "    best_loss = None\n",
        "    val_acc_list, net_list = [], []\n",
        "\n",
        "    if args.all_clients:\n",
        "        print(\"Aggregation over all clients\")\n",
        "        w_locals = [w_glob for i in range(args.num_users)]\n",
        "    for iter in range(args.epochs):\n",
        "        loss_locals = []\n",
        "        if not args.all_clients:\n",
        "            w_locals = []\n",
        "        m = max(int(args.frac * args.num_users), 1)\n",
        "        idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
        "        for idx in idxs_users:\n",
        "            local = LocalUpdate(args=args, dataset=dataset_train, idxs=dict_users[idx])\n",
        "            w, loss = local.train(net=copy.deepcopy(net_glob).to(args.device))\n",
        "            if args.all_clients:\n",
        "                w_locals[idx] = copy.deepcopy(w)\n",
        "            else:\n",
        "                w_locals.append(copy.deepcopy(w))\n",
        "            loss_locals.append(copy.deepcopy(loss))\n",
        "        # update global weights\n",
        "        w_glob = FedAvg(w_locals)\n",
        "\n",
        "        # copy weight to net_glob\n",
        "        net_glob.load_state_dict(w_glob)\n",
        "\n",
        "        # print loss\n",
        "        loss_avg = sum(loss_locals) / len(loss_locals)\n",
        "        print('Round {:3d}, Average loss {:.3f}'.format(iter, loss_avg))\n",
        "        loss_train.append(loss_avg)\n",
        "\n",
        "    # plot loss curve\n",
        "    plt.figure()\n",
        "    plt.plot(range(len(loss_train)), loss_train)\n",
        "    plt.ylabel('train_loss')\n",
        "    plt.savefig('./save/fed_{}_{}_{}_C{}_iid{}.png'.format(args.dataset, args.model, args.epochs, args.frac, args.iid))\n",
        "\n",
        "    # testing\n",
        "    net_glob.eval()\n",
        "    acc_train, loss_train = test_img(net_glob, dataset_train, args)\n",
        "    acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
        "    print(\"Training accuracy: {:.2f}\".format(acc_train))\n",
        "    print(\"Testing accuracy: {:.2f}\".format(acc_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRmmBbF-BdUQ",
        "outputId": "b9391f0c-0809-4f92-c817-734480bfc256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (layer_input): Linear(in_features=784, out_features=200, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (layer_hidden): Linear(in_features=200, out_features=10, bias=True)\n",
            ")\n",
            "Round   0, Average loss 0.113\n",
            "Round   1, Average loss 0.091\n",
            "Round   2, Average loss 0.090\n",
            "Round   3, Average loss 0.061\n",
            "Round   4, Average loss 0.065\n",
            "Round   5, Average loss 0.056\n",
            "Round   6, Average loss 0.051\n",
            "Round   7, Average loss 0.056\n",
            "Round   8, Average loss 0.064\n",
            "Round   9, Average loss 0.037\n",
            "Round  10, Average loss 0.043\n",
            "Round  11, Average loss 0.050\n",
            "Round  12, Average loss 0.045\n",
            "Round  13, Average loss 0.054\n",
            "Round  14, Average loss 0.070\n",
            "Round  15, Average loss 0.041\n",
            "Round  16, Average loss 0.047\n",
            "Round  17, Average loss 0.046\n",
            "Round  18, Average loss 0.045\n",
            "Round  19, Average loss 0.031\n",
            "Training accuracy: 79.77\n",
            "Testing accuracy: 79.48\n"
          ]
        }
      ]
    }
  ]
}